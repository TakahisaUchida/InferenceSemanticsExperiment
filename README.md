# Inference Semantics Experiment
This repository is for the inference semantics experiments. You can run them with InferenceSemanticsAnalysis-all-withChwilla.ipynb and InferenceSemanticsAnalysis-all-correl.ipynb in Experiments folder. The former is for Experiment 1: Relation between Chwilla semantics and Metusalem/McKoon inference by Static and Contextual LMs. The latter is for Experiment 2: Relation between Metusalem semantics and Metusalem/McKoon inference with Static and Contextual LMs.

Each folder below generates data which is necessary for the two experiments.
ChwillaTest: Chiwilla task
embeddingsExperiments: Metusalem task
McKoon1986-pipeline: McKoon task
BERTexperiments: BERT condition

## Pretrained Data
This experiment can be conducted by corpuses below.

### Word2vec and GloVe
1. enwiki_20180420_100d
2. enwiki_20180420_300d
3. enwiki_20180420_500d
4. enwiki_20180420_nolg_100d
5. enwiki_20180420_nolg_300d
6. enwiki_20180420_nolg_500d
7. enwiki_20180420_win10_100d
8. enwiki_20180420_win10_300d
9. enwiki_20180420_win10_500d
10. en_core_web_lg
11. en_core_web_md
12. en_core_web_sm
13. GENSIM-fasttext-wiki-news-subwords-300
14. GENSIM-word2vec-google-news-300
15. GENSIM-glove-wiki-gigaword-50
16. GENSIM-glove-wiki-gigaword-100
17. GENSIM-glove-wiki-gigaword-200
18. GENSIM-glove-wiki-gigaword-300
19. GENSIM-glove-twitter-25
20. GENSIM-glove-twitter-50
21. GENSIM-glove-twitter-100
22. GENSIM-glove-twitter-200

### BERT
1. nli-bert-base
2. nli-bert-base-cls-pooling
3. nli-bert-base-max-pooling
4. nli-bert-large
5. nli-bert-large-cls-pooling
6. nli-bert-large-max-pooling
7. nli-distilbert-base
8. nli-distilbert-base-max-pooling
9. nli-distilroberta-base-v2
10. nli-mpnet-base-v2
11. nli-roberta-base
12. nli-roberta-base-v2
13. nli-roberta-large
14. paraphrase-distilroberta-base-v1
15. paraphrase-xlm-r-multilingual-v1
16. stsb-bert-base
17. stsb-bert-large
18. stsb-distilbert-base
19. stsb-distilroberta-base-v2
20. stsb-mpnet-base-v2
21. stsb-roberta-base
22. stsb-roberta-base-v2
23. stsb-roberta-large
